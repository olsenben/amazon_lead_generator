{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bad06a-4a13-4aca-93e0-3dbffd7c17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#define api key\n",
    "api_key = 'your_api_key'\n",
    "\n",
    "#define marketplace domain ID 1=\"US'\n",
    "domain_id = 1\n",
    "\n",
    "#generate page number\n",
    "#Keepa API uses pagination to help control the number of results returned. Max results is 10000. \n",
    "#be mindful that pagination and page results combined do not exceed 10000\n",
    "#if you request the last page for more results than it contains, your query will return zero results\n",
    "#with this query I have noted that 15 is the max number of pages with a page size of 200 that you can request\n",
    "#because the query will return the same products if run sequentially, I have added a random page generator to diversify results\n",
    "#this is in lieue of actually devising a way to check if I have requested an asin in the past before. Will revisit if n\n",
    "pg_number = random.randint(1, 15)\n",
    "\n",
    "\n",
    "#create query parameters\n",
    "query_params = {\n",
    "    \"categories_exclude\": [ #filter unwanted categories. Check Keepa category IDs for more info\n",
    "        \"668145011\", #aprons\n",
    "        \"374742011\", #sports apparel \n",
    "        \"5768995011\", #caps and hats\n",
    "        \"13727921011\", #Alexa Skills\n",
    "        \"2350149011\", #Apps & Games\n",
    "        \"18145289011\", #Audible Books & Originals\n",
    "        \"283155\", #Books\n",
    "        \"5174\", #CDs & Vinyl\n",
    "        \"7141123011\", #Clothing, Shoes & Jewelry\n",
    "        \"4991425011\", #Collectibles & Fine Art\n",
    "        \"163856011\", #Digital Music\n",
    "        \"2238192011\", #Gift Cards\n",
    "        \"11260432011\", #Handmade Products\n",
    "        \"133140011\", #Kindle Store\n",
    "        \"599858\", #Magazine Subscriptions\n",
    "        \"2625373011\", #Movies & TV\n",
    "        \"229534\", #Software\n",
    "        \"468642\", #Video Games\n",
    "        \"9013971011\" #Video Shorts\n",
    "    ],\n",
    "    \"productType\": \"0\", #physical products only\n",
    "    \"avg180_NEW_gte\": 15, #minimum price\n",
    "    \"imageCount_gte\": 1, #min image count\n",
    "    \"imageCount_lte\": 4, #max image count\n",
    "    \"current_SALES_gte\": 1000, #min sales rank\n",
    "    \"current_SALES_lte\": 100000, #max Sales Rank\n",
    "    \"avg30_SALES_gte\": 1000, #min average 30 day sales rank\n",
    "    \"avg30_SALES_lte\": 100000,  #max average 30 day sales rank\n",
    "    \"monthlySold_gte\": 50, #min monthly sales\n",
    "    \"current_RATING_gte\": 40, #min rating\n",
    "    \"current_COUNT_REVIEWS_gte\": 25, #min reviews\n",
    "    \"brand\": \"✜Bath & Body Works\", #exlcude bath and bodyworks cause theres so many listings\n",
    "    \"buyBoxSellerId\": [\n",
    "        \"-ATVPDKIKX0DER\", #exclude\n",
    "        \"-A3SLTBYT1P4ASM\" #exclude\n",
    "    ],\n",
    "    \"current_BUY_BOX_SHIPPING_gte\": 0,\n",
    "    \"offerCountFBA_gte\": 5, #min FBA offers\n",
    "    \"launchpad\": False, \n",
    "    \"itemWeight_gte\": 0,\n",
    "    \"itemWeight_lte\": 20, #max pacajage weight\n",
    "    \"isHazMat\": False,\n",
    "    \"isAdultProduct\": False,\n",
    "    \"productType\": [\n",
    "        \"0\"\n",
    "    ],\n",
    "    \"singleVariation\": True, #only return 1 asin per variation\n",
    "    \"sort\": [ #sort by sales\n",
    "        [\n",
    "            \"current_SALES\",\n",
    "            \"asc\"\n",
    "        ]\n",
    "    ],\n",
    "    \"lastOffersUpdate_gte\": 6969326,\n",
    "    \"lastRatingUpdate_gte\": 6844106,\n",
    "    \"page\": pg_number,\n",
    "    \"perPage\": 200\n",
    "}\n",
    "\n",
    "#convert query to json format \n",
    "query_json = urllib.parse.quote(json.dumps(query_params))\n",
    "\n",
    "#construct get request URL\n",
    "api_endpoint = f'https://api.keepa.com/query?key={api_key}&domain={domain_id}&selection={query_json}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf3ba7b-e4c7-4a21-87a7-f8929e758ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send HTTP GET request\n",
    "response = requests.get(api_endpoint)\n",
    "response_data = response.json()\n",
    "\n",
    "# Parse the response JSON\n",
    "response_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae608e73-3c63-4af3-9d46-3f516e2db710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of ASINS from parsed response\n",
    "df= pd.DataFrame(response_data['asinList'], columns=['asinList'])\n",
    "\n",
    "#Add column with link to asin\n",
    "df['asinLink'] = df['asinList'].apply(lambda x: \"https://www.amazon.com/dp/\" + x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5426bd-ff2a-40e4-939d-c5896f669708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up the progress bar for DataFrame's apply method\n",
    "tqdm.pandas(desc=\"Checking brand registration\")\n",
    "\n",
    "#function to scrape the page from the asin link and look for storefront \n",
    "def is_brand_registered(asin_url):\n",
    "    try:\n",
    "        # Fetch the HTML content of the product page with scrapeops proxy\n",
    "        response = requests.get(\n",
    "            url = 'https://proxy.scrapeops.io/v1/',\n",
    "            params = {\n",
    "                'api_key' : 'your_api_key',\n",
    "                'url' : asin_url,\n",
    "            },\n",
    "            timeout=30  # Set timeout to avoid hanging requests\n",
    "        )\n",
    "        #store html retrieved by scrapeops\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Check for the presence of \"visit the [brand name] store\" text by element tag <a>, id \"bylineInfo\", class \"a-link-normal\"\n",
    "        store_text = soup.find(\"a\", {\"id\": \"bylineInfo\", \"class\": \"a-link-normal\"}, string=lambda text: text and \"Visit the \" in text and \" Store\" in text)\n",
    "        return bool(store_text)\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error for {asin_url}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching or parsing page {asin_url}: {e}\")\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a32f2a3-0e34-4622-9004-10c969437f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking brand registration: 100%|███████████████████████████████████████████████████| 200/200 [24:43<00:00,  7.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Filter ASINs associated with brand registered brands\n",
    "filtered_asins = df[~df['asinLink'].progress_apply(is_brand_registered)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27d6664-e78f-4792-b71e-2415b371b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_to_csv_with_unique_name(dataframe, base_path):\n",
    "    #save dataframe to csv with a unique name if the filename already exists\n",
    "    #params: \n",
    "    #-dataframe: dataframe to export\n",
    "    #-base_path: directory to export to\n",
    "\n",
    "    #returns\n",
    "    #-final file path for exporting\n",
    "    directory, base_filename = os.path.split(base_path)\n",
    "    name, ext = os.path.splitext(base_filename)\n",
    "\n",
    "    #check that directory exists\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory) \n",
    "    final_path = base_path\n",
    "    counter = 1\n",
    "\n",
    "   # Generate a new name if the file already exists\n",
    "    while os.path.exists(final_path):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        final_path = os.path.join(directory, f\"{name}_{timestamp}_{counter}{ext}\")\n",
    "        counter += 1\n",
    "\n",
    "    # Save the file\n",
    "    dataframe.to_csv(final_path, index=False)\n",
    "    print(f\"File saved as: {final_path}\")\n",
    "    return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31180b60-5de1-4969-8acb-db4a177254c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as: C:\\Users\\benol\\Downloads\\filtered_asins_20241125_165451_1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\benol\\\\Downloads\\\\filtered_asins_20241125_165451_1.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#directory for export\n",
    "base_path = r'C:\\Users\\benol\\Downloads\\filtered_asins.csv'\n",
    "\n",
    "\n",
    "save_to_csv_with_unique_name(filtered_asins, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bbcc6e-a3ab-49a5-8e37-587507294db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
